{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 7\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 11.05.2017\n",
    "\n",
    "Срок сдачи: 23:59MSK 28.05.2017\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 7 посвящено задаче построения рекомендаций и различным подходам к её решению. В рамках данного задания вы:\n",
    " * опробуете различные подходы к построению рекомендаций в задаче рекомендаций фильмов;\n",
    " * оцените качество работы различных подходов на различных группах пользователей, изучите наличие известных недостатков рекомендательных систем;\n",
    " * познакомитесь со способами оценивания качества работы полученных рекомендательных систем, изучите их достоинства и недостатки.\n",
    " \n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW7_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW7_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лабораторной работе будет рассмотрена задача предсказания оценки, которую пользователь поставит фильму. Особенность этой задачи в том, что объекты выборки описываются категориальными признаками, принимающими большое число значений (например: идентификатор пользователя, идентификатор фильма, тэги, киноперсоны).\n",
    "\n",
    "Мы будем работать с датасетом [MovieLens + IMDb/Rotten Tomatoes](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip) ([описание](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt)). Набор содержит данные о предпочтениях пользователей сервиса рекомендации кинофильмов [MovieLens](http://www.movielens.org/). Пользовательские оценки для фильмов принимают значения в интервале от 0.5 до 5.0, они записаны в файле *user_ratedmovies.dat* (а также в *user_ratedmovies-timestamps.dat*,  где для каждой оценки записана дата и время в формате timestamp), остальные файлы содержат дополнительную информацию о фильмах, которую можно использовать как признаки. Заметьте: кроме оценок (и тегов), про пользователя ничего не известно.\n",
    "\n",
    "На основании этих данных необходимо построить модель, предсказывающую оценку пользователя фильму, который он еще не смотрел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценивание качества рекомендаций\n",
    "\n",
    "Будем считать, что пользователю сервиса доступен блок рекомендаций, который может содержать рекомендации не более чем 5 фильмов.\n",
    "\n",
    "Выберем некоторого пользователя $u$ и обозначим известные для него рейтинги за $R^u$. В качестве тестовых рейтингов $R^u_{test}$ для этого пользователя рассмотрим 5 рейтингов, поставленные последними по времени, в качестве валидационных $R^u_{val}$ — предпоследние 5 рейтингов. Остальные известные рейтинги этого пользователя будут составлять обучающую выборку $R^u_{train}$.\n",
    "\n",
    "Для подбора гиперпараметров в рамках данного задания будем использовать валидационную выборку, предварительно обучив модель на обучающей выборке, а для финальной оценки качества — тестовую выборку, предварительно обучив модель на обучающей и валидационной выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (0.5 балла)** Загрузите данные и сформируйте 3 разреженные матрицы пользователи—фильмы для обучающих, валидационных и тестовых рейтингов пользователей соответственно, где в каждой ячейке стоит рейтинг, если он известен, или ноль, если неизвестен. Отметим, что в этом случае для валидационной и тестовой матриц в каждой строке должно быть ровно 5 ненулевых значений. Рассматривайте только тех пользователей, которые поставили оценки $\\ge 11$ фильмам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные об оценках фильмов пользователями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1162160236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1162160624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1162161008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1162160212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1162160970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating      timestamp\n",
       "0      75        3     1.0  1162160236000\n",
       "1      75       32     4.5  1162160624000\n",
       "2      75      110     4.0  1162161008000\n",
       "3      75      160     2.0  1162160212000\n",
       "4      75      163     4.0  1162160970000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('user_ratedmovies-timestamps.dat', sep='\\t')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как ID пользователей и ID фильмов в нашем датасете идут не подряд, изменим их, чтобы разреженные матрицы были поменьше (каждый userID заменим на его место в отсортированном списке всех наших userID, то же самое сделаем с movieID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_userIDs = {}\n",
    "userIDs = list(set(ratings['userID']))\n",
    "userIDs.sort()\n",
    "for i in range(len(userIDs)):\n",
    "    new_userIDs[userIDs[i]] = i\n",
    "\n",
    "new_movieIDs = {}\n",
    "movieIDs = list(set(ratings['movieID']))\n",
    "movieIDs.sort()\n",
    "for i in range(len(movieIDs)):\n",
    "    new_movieIDs[movieIDs[i]] = i\n",
    "ratings['compressed_userID'] = [new_userIDs[x] for x in ratings['userID']]\n",
    "ratings['compressed_movieID'] = [new_movieIDs[x] for x in ratings['movieID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем наш датасет по пользователям, используя DataFrame.groupby, и определим оценки, идущие в обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834468, 6)\n",
      "(10565, 6)\n",
      "(10565, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=ratings.columns)\n",
    "val_df = pd.DataFrame(columns=ratings.columns)\n",
    "test_df = pd.DataFrame(columns=ratings.columns)\n",
    "grouped = list(ratings.groupby('compressed_userID'))\n",
    "for item in grouped:\n",
    "    df = item[1]\n",
    "    if df.shape[0] < 11:\n",
    "        continue\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    to_test = df[-5:]\n",
    "    to_val = df[-10:-5]\n",
    "    to_train = df[:-10]\n",
    "    train_df = train_df.append(to_train)\n",
    "    test_df = test_df.append(to_test)\n",
    "    val_df = val_df.append(to_val)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, сформируем разреженные матрицы для обучающей, тестовой и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(new_userIDs)\n",
    "n_movies = len(new_movieIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sm = sparse.csr_matrix((train_df['rating'].values, \\\n",
    "                            (train_df['compressed_userID'].values,\\\n",
    "                             train_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))\n",
    "test_sm = sparse.csr_matrix((test_df['rating'].values, \\\n",
    "                            (test_df['compressed_userID'].values,\\\n",
    "                             test_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))\n",
    "val_sm = sparse.csr_matrix((val_df['rating'].values, \\\n",
    "                            (val_df['compressed_userID'].values,\\\n",
    "                             val_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения качества рекомендаций в этом задании будем использовать метрики RMSE@k и nDCG@k для $k=5$, описанные ниже.\n",
    "\n",
    "#### RMSE@k\n",
    "\n",
    "Поскольку нас интересуют лишь фильмы, попавшие в блок рекомендаций, качество работы модели можно оценивать при помощи RMSE на $k$ фильмах с наибольшим предсказанным рейтингом, где $k$ — размер блока рекомендаций. Отсортируем предсказанные моделью рейтинги $\\hat{r}_{ui}$ в порядке убывания и обозначим $i$-ый элемент в полученной последовательности за $\\hat{r}_{u(i)},$ а соответствующее этому фильму истинное значение рейтинга — за $r_{u(i)}$. Тогда RMSE@k вычисляется следующим образом:\n",
    "\n",
    "$$ \\text{RMSE@k}(u) = \\sqrt{ \\frac{1}{k} \\sum_{i=1}^k (r_{u(i)} - \\hat{r}_{u(i)})^2 },$$\n",
    "$$ \\text{RMSE@k} = \\frac{1}{|U|} \\sum_{u \\in U} \\text{RMSE@k}(u),$$\n",
    "где $U$ — множество пользователей. При вычислении данной метрики все неизвестные оценки будем полагать равными 0.\n",
    "\n",
    "#### nDCG@k\n",
    "\n",
    "Для оценки качества рекомендаций также можно использовать метрику качества ранжирования. Ожидается, что хороший алгоритм должен выдать релевантные фильмы вверху списка.\n",
    "\n",
    "Как и ранее, отсортируем предсказанные моделью рейтинги $\\hat{r}_{ui}$ в порядке убывания и обозначим $i$-ый элемент в полученной последовательности за $\\hat{r}_{u(i)},$ а соответствующее этому фильму истинное значение рейтинга — за $r_{u(i)}.$\n",
    "\n",
    "Напомним, что\n",
    "\n",
    "$$\\text{DCG@k}(u) = \\sum_{i=1}^k g(r_{u(i)}) d(i),$$\n",
    "$$\\text{nDCG@k}(u) = \\frac{\\text{DCG@k}(u)}{\\max \\text{DCG@k}(u)},$$\n",
    "$$\\text{nDCG@k} = \\frac{1}{|U|} \\sum_{u \\in U} \\text{nDCG@k}(u),$$\n",
    "где $g(r)$ — функция полезности фильма, а  $d(i)$ — штраф за позицию.\n",
    "\n",
    "В рамках данного практического задания положим $g(r) = 2^r-1, \\, d(i) = \\frac{1}{\\log_2 (i+1)}.$ При вычислении данной метрики все неизвестные оценки будем полагать равными 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (1 балл)** Реализуйте функции rmse_score и ndcg_score, вычисляющие значения описанных выше метрик. Каждая из функций в качестве параметров должна принимать:\n",
    " * y_true — матрицу тестовых рейтингов (сформированную аналогично матрице тестовых рейтингов из предыдущего пункта; функция должна корректно работать и для разреженных, и для плотных матриц);\n",
    " * y_predicted — матрицу предсказаний модели в аналогичном формате (функция должна корректно работать и для разреженных, и для плотных матриц);\n",
    " * k — параметр $k$ в определениях метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_predicted, k=5):\n",
    "    if type(y_predicted) == type(sparse.csr_matrix([])):\n",
    "        y_predicted = y_predicted.toarray()\n",
    "    else:\n",
    "        y_predicted = np.array(y_predicted)\n",
    "    if type(y_true) == type(sparse.csr_matrix([])):\n",
    "        y_true = y_true.toarray()\n",
    "    else:\n",
    "        y_true = np.array(y_true)\n",
    "    sum_rmses = 0\n",
    "    n = y_true.shape[0]\n",
    "    diff_sqrs = (y_predicted - y_true) ** 2\n",
    "    argsort = y_predicted.argsort(axis=1)[:, ::-1]\n",
    "    for i in range(n):\n",
    "        most_recommended = argsort[i][:k]\n",
    "        sum_rmses += np.sqrt(diff_sqrs[i][most_recommended].mean())\n",
    "    return sum_rmses / n\n",
    "\n",
    "def ndcg_score(y_true, y_predicted, k=5):\n",
    "    if type(y_predicted) == type(sparse.csr_matrix([])):\n",
    "        y_predicted = y_predicted.toarray()\n",
    "    else:\n",
    "        y_predicted = np.array(y_predicted)\n",
    "    if type(y_true) == type(sparse.csr_matrix([])):\n",
    "        y_true = y_true.toarray()\n",
    "    else:\n",
    "        y_true = np.array(y_true)\n",
    "    g = lambda r: 2 ** r - 1\n",
    "    d = lambda i: 1 / np.log2(i + 2)\n",
    "    max_dcg = g(5) * d(np.arange(k)).sum()\n",
    "    if type(y_predicted) == type(sparse.csr_matrix([])):\n",
    "        y_predicted = y_predicted.toarray()\n",
    "    if type(y_true) == type(sparse.csr_matrix([])):\n",
    "        y_true = y_true.toarray()\n",
    "    n, m = y_true.shape\n",
    "    dcg = []\n",
    "    argsort = y_predicted.argsort(axis=1)[:, ::-1]\n",
    "    for i in range(n):\n",
    "        most_recommended = argsort[i][:k]\n",
    "        true_ratings = y_true[i][most_recommended]\n",
    "        dcg.append(np.sum(g(true_ratings) * d(np.arange(k))))\n",
    "    dcg = np.array(dcg)\n",
    "    return (dcg / max_dcg).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (0.5 балла)** Разделите индексы пользователей в матрицах из п.1 на 3 группы:\n",
    "1. пользователи, оценившие менее 20 фильмов;\n",
    "2. 50 случайных пользователей, оценивших фильмы, имеющие не более 5 оценок;\n",
    "3. все остальные пользователи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "less_20_rates = [x[0] for x in grouped if x[1].shape[0] < 20]\n",
    "print(len(less_20_rates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая группа пуста - каждый пользователь оценил хотя бы 20 фильмов.\n",
    "\n",
    "Отберем вторую группу. Для этого посмотрим, сколько раз был оценен каждый фильм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из 10109 фильмов 2248 имеют не более 5 оценок\n"
     ]
    }
   ],
   "source": [
    "all_ratings_sm = sparse.csr_matrix((ratings['rating'], (ratings['compressed_userID'], ratings['compressed_movieID'])))\n",
    "ratings_by_movies = all_ratings_sm.nonzero()[1]\n",
    "counter = collections.Counter(ratings_by_movies)\n",
    "rarely_rated = [i for i in range(n_movies) if counter[i] <= 5]\n",
    "print('Из {} фильмов {} имеют не более 5 оценок'.format(n_movies, len(rarely_rated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 916 пользователей, оценивших непопулярные фильмы\n"
     ]
    }
   ],
   "source": [
    "our_users = set()\n",
    "for movie in rarely_rated:\n",
    "    for user in all_ratings_sm.getcol(movie).tocsc().indices:\n",
    "        our_users.add(user)\n",
    "print('Всего {} пользователей, оценивших непопулярные фильмы'.format(len(our_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "group2 = set(random.sample(our_users, 50))\n",
    "group3 = set(range(n_users)) - group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой группы сделаем отдельные матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group2_train_sm = train_sm[list(group2)]\n",
    "group2_test_sm = test_sm[list(group2)]\n",
    "group2_val_sm = val_sm[list(group2)]\n",
    "group3_train_sm = train_sm[list(group3)]\n",
    "group3_test_sm = test_sm[list(group3)]\n",
    "group3_val_sm = val_sm[list(group3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. (0.5 балла)** Постройте рекомендации на основе **most popular** метода, при котором предсказанный рейтинг для некоторого фильма $i$ одинаков для всех пользователей и совпадает со средним значением рейтинга по всем пользователям, оценившим этот фильм, и вычислите значения метрик RMSE@5 и nDCG@5 для тестовой матрицы из п. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "nonzero = train_sm.nonzero()\n",
    "ones = sparse.csr_matrix((np.ones_like(nonzero[0]), nonzero), shape=(n_users, n_movies))\n",
    "avg_rating = train_sm.sum(axis=0) / ones.sum(axis=0)\n",
    "avg_rating = np.array(np.nan_to_num(avg_rating))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_popular_prediction = np.tile(avg_rating, n_users).reshape((n_users, n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = rmse_score(test_sm, most_popular_prediction)\n",
    "ndcg = ndcg_score(test_sm, most_popular_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.99816123591\n",
      "NDCG: 0.0005141536439\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', rmse)\n",
    "print('NDCG:', ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод most popular предсказывает плохо, что не удивительно при сильно разреженной матрице."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. (1 балл)** Постройте рекомендации на основе user-based коллаборативной фильтрации (подробно метод описан в [лекции 19](https://github.com/esokolov/ml-course-hse/blob/master/2016-spring/lecture-notes/lecture19-recommender.pdf), в качестве функции сходства используйте корреляцию Пирсона), при этом итоговое предсказание модели $\\hat{r}_{ui}$ вычисляйте по следующей формуле:\n",
    "$$\\hat{r}_{ui} = \\bar{r}_{u} + \\frac{\\sum_{v \\in U(u)} w_{uv} (r_{vi} - \\bar{r}_v)}{\\sum_{v \\in U(u)} w_{uv}},$$\n",
    "где $\\bar{r}_u$ — средний ретинг пользователя $u$, $w_{uv}$ — мера сходства пользователей $u$ и $v$, $U(u) = \\{ v \\in U \\, | \\, w_{uv} > \\alpha\\}$ — коллаборация пользователя $u$. Значение параметра $\\alpha$ подберите на валидационной выборке.\n",
    "\n",
    "Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из группы 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Для начала построим матрицу похожестей пользователей $W = (w_{uv})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.corrcoef(train_sm.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $\\alpha$ от 0.1 до 0.5 с шагом 0.05 построим предсказание и посмотрим его RMSE и NDCG на валидации. Выберем то $\\alpha$, на котором RMSE больше всего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_based_collaborative_filtering(train_sm, alpha):\n",
    "    r_mean = train_sm.sum(axis=1) / ones.sum(axis=1)\n",
    "    r_mean = np.array(r_mean).T[0]\n",
    "    prediction = []\n",
    "    for u in range(n_users):\n",
    "        U = np.array(W[u] > alpha).nonzero()[0]\n",
    "        w = W[u][U]\n",
    "        R = train_sm[U, :]\n",
    "        sum_of_collab = w @ (R.T - r_mean[U]).T\n",
    "        sum_of_collab = np.array(sum_of_collab)[0]\n",
    "        our_prediction = r_mean[u] + sum_of_collab / w.sum()\n",
    "        prediction.append(our_prediction)\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.5, rmse: 4.857321826935504, ndcg: 0.0\n",
      "alpha = 0.45, rmse: 4.753820943564251, ndcg: 0.0\n",
      "alpha = 0.4, rmse: 4.603877807715933, ndcg: 0.00011485239243834863\n",
      "alpha = 0.35000000000000003, rmse: 4.43084755511802, ndcg: 0.00047831728707678657\n",
      "alpha = 0.30000000000000004, rmse: 4.24627189960414, ndcg: 0.0008010516560646881\n",
      "alpha = 0.25000000000000006, rmse: 4.053993266861639, ndcg: 0.0013310159965524379\n",
      "alpha = 0.20000000000000007, rmse: 3.8589181675838233, ndcg: 0.002239386690723654\n",
      "alpha = 0.15000000000000008, rmse: 3.684971502953894, ndcg: 0.003987151757503321\n",
      "alpha = 0.10000000000000009, rmse: 3.553474386906832, ndcg: 0.00569793709359876\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.arange(0.5, 0.09, -0.05):\n",
    "    min_rmse = 5\n",
    "    prediction = user_based_collaborative_filtering(train_sm, alpha)\n",
    "    rmse = rmse_score(val_sm, prediction)\n",
    "    ndcg = ndcg_score(val_sm, prediction)\n",
    "    print('alpha = {}, rmse: {}, ndcg: {}'.format(alpha, rmse, ndcg))\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        best_alpha = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим прогноз с best_alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = user_based_collaborative_filtering(train_sm, best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. (0.5 балла)** Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1 и 2 (по отдельности) для рекомендаций, построенных в п. 5. Ощутимо ли различие со значениями метрик из п. 5? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группа 1 пустая. Посмотрим RMSE и nDCG на группе 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_for_group2 = prediction[list(group2)]\n",
    "rmse = rmse_score(group2_test_sm, prediction_for_group2)\n",
    "ndcg = ndcg_score(group2_test_sm, prediction_for_group2)\n",
    "print('RMSE:', rmse)\n",
    "print('NDCG:', ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** RMSE почти не изменилось. NDCG стало нулевым. Причина, скорее всего, в том, что у пользователей, которые смотрят непопулярные фильмы, очень мало других похожих пользователей, и user-based подход не может на них хорошо работать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. (2 балла)** Постройте рекомендации при помощи модели со скрытыми переменными. Напомним, что в данном методе решается следующая оптимизационная задача:\n",
    "$$\\sum_{(u, i) \\in R} (r_{ui} - \\bar{r}_u - \\bar{r}_i - \\langle p_u, q_i\\rangle)^2 + \\lambda \\sum_{u \\in U} \\| p_u\\|^2 + \\mu \\sum_{i \\in I} \\| q_i\\|^2 \\to \\min_{p_u, q_i}$$\n",
    "\n",
    "Реализуйте построение рекомендаций при помощи любого из изученных методов оптимизации для данной задачи (SGD, ALS, HALS), подберите значения параметров регуляризации на валидационной выборке и постройте график зависимости метрик RMSE@5 и nDCG@5 от значения ранга разложения на валидационной выборке (рассмотрите как минимум 10 различных значений ранга разложения). Также разрешается использовать любые свободно распространяемые библиотеки при условии, что функционал совпадает с приведенным выше и используется один из приведенных методов оптимизации. Обращаем ваше внимание, что в оптимизационной задаче суммирование ведется лишь по известным элементам матрицы $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Будем использовать стохастический градиентный спуск (SGD). Изначально вектора $p_u$ и $q_i$ заполнены случайными значениями. На каждом шаге выбирается случайная пара $(u, i)$ из тех, для которых $r_{ui}$ известно. Вектора $p_u$ и $q_i$ изменяются в сторону антиградиента:\n",
    "$$p_{uk} \\text{ += } \\eta(q_{ik}(r_{ui} - \\bar{r}_u - \\bar{r}_i - \\langle p_u, q_i\\rangle) - \\lambda p_{uk};\\ \\ \\ q_{ik} \\text{ += } \\eta(p_{uk}(r_{ui} - \\bar{r}_u - \\bar{r}_i - \\langle p_u, q_i\\rangle) - \\mu q_{ik})$$\n",
    "Ответом будет матрица $p^T q$, отнормированная так, чтобы ее максимум был 5.\n",
    "\n",
    "Возьмем для начала следующие параметры оптимизации:\n",
    "$$\\eta = 0.05, \\lambda = \\mu = 1, d = 20$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD_prediction(R, n_iter=100000, eta_0=0.05, lmbd=1, mu=1, d=20, verbose=0):\n",
    "    means_by_user = R.sum(axis=1) / ones.sum(axis=1)\n",
    "    means_by_movie = R.sum(axis=0) / ones.sum(axis=0)\n",
    "    means_by_user = np.nan_to_num(means_by_user)\n",
    "    means_by_movie = np.nan_to_num(means_by_movie)\n",
    "    means_by_user = np.array(means_by_user).T[0]\n",
    "    means_by_movie = np.array(means_by_movie)[0]\n",
    "    nonzero_elements = np.array([R.nonzero()[0], R.nonzero()[1]]).T\n",
    "    p = np.random.random((n_users, d)) / 2\n",
    "    q = np.random.random((n_movies, d)) / 2\n",
    "    tiled_mu = np.tile(means_by_user, n_movies).reshape((n_movies, n_users)).T\n",
    "    tiled_mm = np.tile(means_by_movie, n_users).reshape((n_users, n_movies))\n",
    "    R_normed = R - tiled_mu - tiled_mm\n",
    "    for iteration in range(n_iter):\n",
    "        eta = eta_0\n",
    "        j = np.random.randint(nonzero_elements.shape[0])\n",
    "        u, i = nonzero_elements[j]\n",
    "        dfunc = (R[u].getcol(i)).toarray()[0][0] - means_by_user[u] - means_by_movie[i] - (p[u] * q[i]).sum()\n",
    "        dp = dfunc * q[i] - lmbd * p[u]\n",
    "        dq = dfunc * p[u] - mu * q[i]\n",
    "        if (dp ** 2).mean() > 100 or (dq ** 2).mean() > 100:\n",
    "            break\n",
    "        p[u] += eta * dp\n",
    "        q[i] += eta * dq\n",
    "        if verbose > 0 and iteration % verbose == 0:\n",
    "            pq = p @ q.T\n",
    "            our_funct = np.sum(np.array(R_normed[R.nonzero()] - pq[R.nonzero()]) ** 2)\n",
    "            print('iteration {}: without reg: {}, with reg: {}'.format(iteration,\\\n",
    "                                                                       our_funct,\\\n",
    "                                                                        our_funct + lmbd * np.sum(p ** 2) + mu * np.sum(q ** 2)))\n",
    "        \n",
    "    result = np.matrix(p) * np.matrix(q.T) + tiled_mu + tiled_mm\n",
    "    return result * 5 / result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicion = SGD_prediction(train_sm, lmbd=0.1, mu=0.1)\n",
    "rmse = rmse_score(train_sm, predicion)\n",
    "print('RMSE:', rmse)\n",
    "ndcg = ndcg_score(train_sm, predicion)\n",
    "print('nDCG:', ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик уже лучше, чем у предыдущих методов. Подберем параметры: при d=20 подберем $\\lambda, \\mu$ на значениях из {0.1, 0.3, 1, 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lmbd in [0.1, 0.3, 1, 3]:\n",
    "    for mu in [0.1, 0.3, 1, 3]:\n",
    "        prediction = SGD_prediction(train_sm, lmbd=lmbd, mu=mu)\n",
    "        rmse = rmse_score(val_sm, prediction)\n",
    "        ndcg = ndcg_score(val_sm, prediction)\n",
    "        print('lambda: {}, mu: {}, rmse: {}, ndcg: {}'.format(lmbd, mu, rmse, ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По совокупности метрик RMSE и nDCG выбираем $\\lambda=3, \\mu=0.1$.\n",
    "Теперь посмотрим на ранг разложения d. Посмотрим значения d от 10 до 100 с шагом 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.arange(10, 101, 10)\n",
    "rmses = []\n",
    "ndcgs = []\n",
    "for d in D:\n",
    "    prediction = SGD_prediction(train_sm, lmbd=3, mu=0.1, d=d)\n",
    "    rmse = rmse_score(val_sm, prediction)\n",
    "    ndcg = ndcg_score(val_sm, prediction)\n",
    "    rmses.append(rmse)\n",
    "    ndcgs.append(ndcg)\n",
    "    print('d = {}; rmse: {}, ndcg: {}'.format(d, rmse, ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики RMSE и nDCG в зависмости от d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('RMSE', fontsize=18)\n",
    "plt.plot(D, rmses)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('nDCG', fontsize=18)\n",
    "plt.plot(D, ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем d = 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. (0.5 балла)** Постройте рекомендации с оптимальными значениями гиперпараметров из п. 7 и вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1, 2 и 3 (по отдельности). Ощутимо ли различие между ними? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = SGD_prediction(train_sm, lmbd=3, mu=0.1, d=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_group2 = rmse_score(group2_test_sm, prediction[list(group2)])\n",
    "ndcg_group2 = ndcg_score(group2_test_sm, prediction[list(group2)])\n",
    "rmse_group3 = rmse_score(group3_test_sm, prediction[list(group3)])\n",
    "ndcg_group3 = ndcg_score(group3_test_sm, prediction[list(group3)])\n",
    "print('group 2:')\n",
    "print('RMSE: {}, nDCG: {}'.format(rmse_group2, ndcg_group2))\n",
    "print('group3:')\n",
    "print('RMSE: {}, nDCG: {}'.format(rmse_group3, ndcg_group3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** На второй группе nDCG становится нулем. Это происходит, во-первых, из-за того, что там всего 50 пользователей и у каждого всего 5 оценок на 10000 фильмов - вероятность того, что фильмы, рекомендованные пользователю, им просмотрены и оценены, очень мала, и во-вторых, потому, что фильмы, которые смотрели пользователи из группы 2, непопулярны, и алгоритм не смог нормально на них настроиться. То, что RMSE на первой группе немного меньше, скорее всего, случайность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. (0.5 балла)** Реализуйте построение рекомендаций путём разложения матрицы рейтингов с помощью [разреженного SVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) (в предположении, что неизвестные рейтинги заменяются на нули) и последующего её восстановления и постройте график зависимости метрик RMSE@5 и nDCG@5 от значения ранга разложения на валидационной выборке (рассмотрите как минимум 10 различных значений ранга разложения). Постройте рекомендации с оптимальными значениями гиперпараметров  и вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1, 2 и 3 (по отдельности). Как полученные значения отличаются от аналогичных из п. 8? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим рекомендации методом TruncatedSVD с рангами разложения от 5 до 50 с шагом 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmses = []\n",
    "ndcgs = []\n",
    "for d in range(5, 51, 5):\n",
    "    svd = TruncatedSVD(n_components=d)\n",
    "    reduced_matrix = svd.fit_transform(train_sm)\n",
    "    prediction = reduced_matrix @ svd.components_\n",
    "    rmse = rmse_score(val_sm, prediction)\n",
    "    ndcg = ndcg_score(val_sm, prediction)\n",
    "    rmses.append(rmse)\n",
    "    ndcgs.append(ndcg)\n",
    "    print('d: {}, RMSE: {}, nDCG: {}'.format(d, rmse, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(reduced_matrix)\n",
    "print(svd.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('RMSE', fontsize=18)\n",
    "plt.plot(range(5, 51, 5), rmses)\n",
    "plt.ylim((0, None))\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('nDCG', fontsize=18)\n",
    "plt.plot(range(5, 51, 5), ndcgs)\n",
    "plt.ylim((0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения обеих метрик, качество предсказания лучше при малых значениях ранга разложения. Возьмем d=5 и посмотрим на значения RMSE и nDCG на 2-й и 3-й группах (первая группа пуста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 5\n",
    "svd = TruncatedSVD(n_components=d)\n",
    "reduced_matrix = svd.fit_transform(train_sm)\n",
    "prediction = reduced_matrix @ svd.components_\n",
    "rmse_group2 = rmse_score(group2_test_sm, prediction[list(group2)])\n",
    "ndcg_group2 = ndcg_score(group2_test_sm, prediction[list(group2)])\n",
    "rmse_group3 = rmse_score(group3_test_sm, prediction[list(group3)])\n",
    "ndcg_group3 = ndcg_score(group3_test_sm, prediction[list(group3)])\n",
    "print('group 2:')\n",
    "print('RMSE: {}, nDCG: {}'.format(rmse_group2, ndcg_group2))\n",
    "print('group 3:')\n",
    "print('RMSE: {}, nDCG: {}'.format(rmse_group3, ndcg_group3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** nDCG на группе 2 заметно выше, RMSE хуже. В предыдущем пункте было наоборот. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. (0.5 балла)** Сформируйте обучающие, валидационные и тестовые матрицы объект-признак для следующих наборов признаков:\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование);\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + средняя оценка пользователя;\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + жанры фильма;\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + жанры фильма + киноперсоны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actors_data = pd.read_csv('movielens_data/movie_actors.dat', sep='\\t', encoding=\"ISO-8859-1\")\n",
    "genres_data = pd.read_csv('movielens_data/movie_genres.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем массив жанров и массив актеров для каждого фильма. Каждому жанру и каждому актеру присвоим свой уникальный номер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_genres = list(set(genres_data.genre))\n",
    "number_of_genre = {}\n",
    "for i in range(len(all_genres)):\n",
    "    number_of_genre[all_genres[i]] = i\n",
    "genres = [[] for i in range(n_movies)]\n",
    "for i in range(genres_data.shape[0]):\n",
    "    movieID = genres_data.movieID[i]\n",
    "    genre = genres_data.genre[i]\n",
    "    if movieID in new_movieIDs:\n",
    "        genres[new_movieIDs[movieID]].append(number_of_genre[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_actors = list(set(actors_data.actor_name))\n",
    "number_of_actor = {}\n",
    "for i in range(len(all_actors)):\n",
    "    number_of_actor[all_actors[i]] = i\n",
    "actors = [[] for i in range(n_movies)]\n",
    "for i in range(actors_data.shape[0]):\n",
    "    movieID = actors_data.movieID[i]\n",
    "    actor_name = actors_data.actor_name[i]\n",
    "    if movieID in new_movieIDs:\n",
    "        actors[new_movieIDs[movieID]].append(number_of_actor[actor_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем несколько функций, кодирующих признаки в sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_user_and_movie_ids(R):\n",
    "    R_coo = R.tocoo()\n",
    "    n_rates = R_coo.data.shape[0]\n",
    "    data = np.ones(2 * n_rates)\n",
    "    rows = np.hstack((np.arange(n_rates), np.arange(n_rates)))\n",
    "    cols = np.hstack((R_coo.row, R_coo.col + n_users))\n",
    "    return sparse.csr_matrix((data, (rows, cols)), shape=(n_rates, n_users + n_movies))\n",
    "\n",
    "def encode_user_means(R):\n",
    "    means = np.array(R.mean(axis=0))[0]\n",
    "    R_coo = R.tocoo()\n",
    "    n_rates = R_coo.data.shape[0]\n",
    "    users = R_coo.row\n",
    "    data = means[users]\n",
    "    rows = np.arange(n_rates)\n",
    "    cols = np.zeros_like(rows)\n",
    "    return sparse.csr_matrix((data, (rows, cols)), shape=(n_rates, 1))\n",
    "\n",
    "def encode_movie_genres(R):\n",
    "    R_coo = R.tocoo()\n",
    "    n_rates = R_coo.data.shape[0]\n",
    "    cols = []\n",
    "    rows = []\n",
    "    for i in range(n_rates):\n",
    "        movie = R_coo.col[i]\n",
    "        n_genres = len(genres[movie])\n",
    "        rows += [i] * n_genres\n",
    "        cols += genres[movie]\n",
    "    data = np.ones_like(np.array(cols))\n",
    "    return sparse.csr_matrix((data, (rows, cols)), shape=(n_rates, len(all_genres)))\n",
    "\n",
    "def encode_movie_actors(R):\n",
    "    R_coo = R.tocoo()\n",
    "    n_rates = R_coo.data.shape[0]\n",
    "    cols = []\n",
    "    rows = []\n",
    "    for i in range(n_rates):\n",
    "        movie = R_coo.col[i]\n",
    "        rows += [i] * len(actors[movie])\n",
    "        cols += actors[movie]\n",
    "    data = np.ones_like(np.array(cols))\n",
    "    return sparse.csr_matrix((data, (rows, cols)), shape=(n_rates, len(all_actors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_userid_movieid = encode_user_and_movie_ids(train_sm)\n",
    "val_userid_movieid = encode_user_and_movie_ids(val_sm)\n",
    "test_userid_movieid = encode_user_and_movie_ids(test_sm)\n",
    "\n",
    "train_uid_mid_mean = sparse.hstack((encode_user_and_movie_ids(train_sm), encode_user_means(train_sm)))\n",
    "val_uid_mid_mean = sparse.hstack((encode_user_and_movie_ids(val_sm), encode_user_means(val_sm)))\n",
    "test_uid_mid_mean = sparse.hstack((encode_user_and_movie_ids(test_sm), encode_user_means(test_sm)))\n",
    "\n",
    "train_uid_mid_genres = sparse.hstack((encode_user_and_movie_ids(train_sm), encode_movie_genres(train_sm)))\n",
    "val_uid_mid_genres = sparse.hstack((encode_user_and_movie_ids(val_sm), encode_movie_genres(val_sm)))\n",
    "test_uid_mid_genres = sparse.hstack((encode_user_and_movie_ids(test_sm), encode_movie_genres(test_sm)))\n",
    "\n",
    "train_uid_mid_actors = sparse.hstack((encode_user_and_movie_ids(train_sm), encode_movie_actors(train_sm)))\n",
    "val_uid_mid_actors = sparse.hstack((encode_user_and_movie_ids(val_sm), encode_movie_actors(val_sm)))\n",
    "test_uid_mid_actors = sparse.hstack((encode_user_and_movie_ids(test_sm), encode_movie_actors(test_sm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем также вектор целевой переменной - столбцы оценок для обучающей, тестовой и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_sm.data\n",
    "y_val = val_sm.data\n",
    "y_test = test_sm.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. (1.5 балла)** Для каждой из выборок из предыдущего пункта постройте рекомендации при помощи факторизационных машин из библиотеки [LibFM](http://libfm.org) с использованием метода оптимизации ALS, подобрав оптимальную размерность разложения на валидационной выборке. Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для оптимальных значений гиперпараметров. Какой набор признаков оказался самым удачным? Как это можно объяснить?\n",
    "При выполнении данного задания вам также может пригодиться библиотека [pywFM](https://github.com/jfloff/pywFM), являющаяся python-обёрткой над LibFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.get('LIBFM_PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((1000, 1000))\n",
    "Y = np.ones(1000)\n",
    "B = A.copy()\n",
    "Y1 = Y.copy()\n",
    "machine = pywFM.FM(task='regression')\n",
    "machine.run(A, Y, B, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "def run_factorization_machine(X_train, X_val, Y_train, Y_val):\n",
    "    D = range(5, 51, 5)\n",
    "    for d in D:\n",
    "        machine = pywFM.FM(task='regression')\n",
    "        machine.run(X_train, Y_train, X_val, Y_val)\n",
    "        print(run.predictions.shape)\n",
    "        break\n",
    "        \n",
    "run_factorization_machine(train_userid_movieid, val_userid_movieid, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторизационная машина не запускается :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. (1 балл)** Приведите сравнение качества всех моделей, руководствуясь значениями описанных метрик. Какие из моделей оказались лучше других по каждой из метрик? Как это можно объяснить?\n",
    "\n",
    "**Ответ**: По метрике RMSE лучшее качество у модели со скрытыми переменными. По метрике nDCG лучшее качество у разреженного SVD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
