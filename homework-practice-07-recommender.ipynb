{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 7\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 11.05.2017\n",
    "\n",
    "Срок сдачи: 23:59MSK 28.05.2017\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 7 посвящено задаче построения рекомендаций и различным подходам к её решению. В рамках данного задания вы:\n",
    " * опробуете различные подходы к построению рекомендаций в задаче рекомендаций фильмов;\n",
    " * оцените качество работы различных подходов на различных группах пользователей, изучите наличие известных недостатков рекомендательных систем;\n",
    " * познакомитесь со способами оценивания качества работы полученных рекомендательных систем, изучите их достоинства и недостатки.\n",
    " \n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW7_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW7_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лабораторной работе будет рассмотрена задача предсказания оценки, которую пользователь поставит фильму. Особенность этой задачи в том, что объекты выборки описываются категориальными признаками, принимающими большое число значений (например: идентификатор пользователя, идентификатор фильма, тэги, киноперсоны).\n",
    "\n",
    "Мы будем работать с датасетом [MovieLens + IMDb/Rotten Tomatoes](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip) ([описание](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt)). Набор содержит данные о предпочтениях пользователей сервиса рекомендации кинофильмов [MovieLens](http://www.movielens.org/). Пользовательские оценки для фильмов принимают значения в интервале от 0.5 до 5.0, они записаны в файле *user_ratedmovies.dat* (а также в *user_ratedmovies-timestamps.dat*,  где для каждой оценки записана дата и время в формате timestamp), остальные файлы содержат дополнительную информацию о фильмах, которую можно использовать как признаки. Заметьте: кроме оценок (и тегов), про пользователя ничего не известно.\n",
    "\n",
    "На основании этих данных необходимо построить модель, предсказывающую оценку пользователя фильму, который он еще не смотрел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценивание качества рекомендаций\n",
    "\n",
    "Будем считать, что пользователю сервиса доступен блок рекомендаций, который может содержать рекомендации не более чем 5 фильмов.\n",
    "\n",
    "Выберем некоторого пользователя $u$ и обозначим известные для него рейтинги за $R^u$. В качестве тестовых рейтингов $R^u_{test}$ для этого пользователя рассмотрим 5 рейтингов, поставленные последними по времени, в качестве валидационных $R^u_{val}$ — предпоследние 5 рейтингов. Остальные известные рейтинги этого пользователя будут составлять обучающую выборку $R^u_{train}$.\n",
    "\n",
    "Для подбора гиперпараметров в рамках данного задания будем использовать валидационную выборку, предварительно обучив модель на обучающей выборке, а для финальной оценки качества — тестовую выборку, предварительно обучив модель на обучающей и валидационной выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (0.5 балла)** Загрузите данные и сформируйте 3 разреженные матрицы пользователи—фильмы для обучающих, валидационных и тестовых рейтингов пользователей соответственно, где в каждой ячейке стоит рейтинг, если он известен, или ноль, если неизвестен. Отметим, что в этом случае для валидационной и тестовой матриц в каждой строке должно быть ровно 5 ненулевых значений. Рассматривайте только тех пользователей, которые поставили оценки $\\ge 11$ фильмам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные об оценках фильмов пользователями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1162160236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1162160624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1162161008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1162160212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1162160970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating      timestamp\n",
       "0      75        3     1.0  1162160236000\n",
       "1      75       32     4.5  1162160624000\n",
       "2      75      110     4.0  1162161008000\n",
       "3      75      160     2.0  1162160212000\n",
       "4      75      163     4.0  1162160970000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('movielens_data/user_ratedmovies-timestamps.dat', sep='\\t')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как ID пользователей и ID фильмов в нашем датасете идут не подряд, изменим их, чтобы разреженные матрицы были поменьше (каждый userID заменим на его место в отсортированном списке всех наших userID, то же самое сделаем с movieID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_userIDs = {}\n",
    "userIDs = list(set(ratings['userID']))\n",
    "userIDs.sort()\n",
    "for i in range(len(userIDs)):\n",
    "    new_userIDs[userIDs[i]] = i\n",
    "\n",
    "new_movieIDs = {}\n",
    "movieIDs = list(set(ratings['movieID']))\n",
    "movieIDs.sort()\n",
    "for i in range(len(movieIDs)):\n",
    "    new_movieIDs[movieIDs[i]] = i\n",
    "ratings['compressed_userID'] = [new_userIDs[x] for x in ratings['userID']]\n",
    "ratings['compressed_movieID'] = [new_movieIDs[x] for x in ratings['movieID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем наш датасет по пользователям, используя DataFrame.groupby, и определим оценки, идущие в обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834468, 6)\n",
      "(10565, 6)\n",
      "(10565, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=ratings.columns)\n",
    "val_df = pd.DataFrame(columns=ratings.columns)\n",
    "test_df = pd.DataFrame(columns=ratings.columns)\n",
    "grouped = list(ratings.groupby('compressed_userID'))\n",
    "for item in grouped:\n",
    "    df = item[1]\n",
    "    if df.shape[0] < 11:\n",
    "        continue\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    to_test = df[-5:]\n",
    "    to_val = df[-10:-5]\n",
    "    to_train = df[:-10]\n",
    "    train_df = train_df.append(to_train)\n",
    "    test_df = test_df.append(to_test)\n",
    "    val_df = val_df.append(to_val)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, сформируем разреженные матрицы для обучающей, тестовой и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(new_userIDs)\n",
    "n_movies = len(new_movieIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sm = sparse.csr_matrix((train_df['rating'].values, \\\n",
    "                            (train_df['compressed_userID'].values,\\\n",
    "                             train_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))\n",
    "test_sm = sparse.csr_matrix((test_df['rating'].values, \\\n",
    "                            (test_df['compressed_userID'].values,\\\n",
    "                             test_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))\n",
    "val_sm = sparse.csr_matrix((val_df['rating'].values, \\\n",
    "                            (val_df['compressed_userID'].values,\\\n",
    "                             val_df['compressed_movieID'].values)),\\\n",
    "                            shape=(n_users, n_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения качества рекомендаций в этом задании будем использовать метрики RMSE@k и nDCG@k для $k=5$, описанные ниже.\n",
    "\n",
    "#### RMSE@k\n",
    "\n",
    "Поскольку нас интересуют лишь фильмы, попавшие в блок рекомендаций, качество работы модели можно оценивать при помощи RMSE на $k$ фильмах с наибольшим предсказанным рейтингом, где $k$ — размер блока рекомендаций. Отсортируем предсказанные моделью рейтинги $\\hat{r}_{ui}$ в порядке убывания и обозначим $i$-ый элемент в полученной последовательности за $\\hat{r}_{u(i)},$ а соответствующее этому фильму истинное значение рейтинга — за $r_{u(i)}$. Тогда RMSE@k вычисляется следующим образом:\n",
    "\n",
    "$$ \\text{RMSE@k}(u) = \\sqrt{ \\frac{1}{k} \\sum_{i=1}^k (r_{u(i)} - \\hat{r}_{u(i)})^2 },$$\n",
    "$$ \\text{RMSE@k} = \\frac{1}{|U|} \\sum_{u \\in U} \\text{RMSE@k}(u),$$\n",
    "где $U$ — множество пользователей. При вычислении данной метрики все неизвестные оценки будем полагать равными 0.\n",
    "\n",
    "#### nDCG@k\n",
    "\n",
    "Для оценки качества рекомендаций также можно использовать метрику качества ранжирования. Ожидается, что хороший алгоритм должен выдать релевантные фильмы вверху списка.\n",
    "\n",
    "Как и ранее, отсортируем предсказанные моделью рейтинги $\\hat{r}_{ui}$ в порядке убывания и обозначим $i$-ый элемент в полученной последовательности за $\\hat{r}_{u(i)},$ а соответствующее этому фильму истинное значение рейтинга — за $r_{u(i)}.$\n",
    "\n",
    "Напомним, что\n",
    "\n",
    "$$\\text{DCG@k}(u) = \\sum_{i=1}^k g(r_{u(i)}) d(i),$$\n",
    "$$\\text{nDCG@k}(u) = \\frac{\\text{DCG@k}(u)}{\\max \\text{DCG@k}(u)},$$\n",
    "$$\\text{nDCG@k} = \\frac{1}{|U|} \\sum_{u \\in U} \\text{nDCG@k}(u),$$\n",
    "где $g(r)$ — функция полезности фильма, а  $d(i)$ — штраф за позицию.\n",
    "\n",
    "В рамках данного практического задания положим $g(r) = 2^r-1, \\, d(i) = \\frac{1}{\\log_2 (i+1)}.$ При вычислении данной метрики все неизвестные оценки будем полагать равными 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (1 балл)** Реализуйте функции rmse_score и ndcg_score, вычисляющие значения описанных выше метрик. Каждая из функций в качестве параметров должна принимать:\n",
    " * y_true — матрицу тестовых рейтингов (сформированную аналогично матрице тестовых рейтингов из предыдущего пункта; функция должна корректно работать и для разреженных, и для плотных матриц);\n",
    " * y_predicted — матрицу предсказаний модели в аналогичном формате (функция должна корректно работать и для разреженных, и для плотных матриц);\n",
    " * k — параметр $k$ в определениях метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_predicted, k=5):\n",
    "    if type(y_predicted) == type(sparse.csr_matrix([])):\n",
    "        y_predicted = y_predicted.toarray()\n",
    "    if type(y_true) == type(sparse.csr_matrix([])):\n",
    "        y_true = y_true.toarray()\n",
    "    n, m = y_true.shape\n",
    "    sum_rmses = 0\n",
    "    diff_sqrs = (y_predicted - y_true) ** 2\n",
    "    argsort = y_predicted.argsort(axis=1)[:, ::-1]\n",
    "    for i in range(n):\n",
    "        most_recommended = argsort[i][:k]\n",
    "        sum_rmses += np.sqrt(diff_sqrs[i][most_recommended].mean())\n",
    "    return sum_rmses / n\n",
    "\n",
    "def ndcg_score(y_true, y_predicted, k=5):\n",
    "    g = lambda r: 2 ** r - 1\n",
    "    d = lambda i: 1 / np.log2(i + 2)\n",
    "    max_dcg = g(5) * d(np.arange(k)).sum()\n",
    "    if type(y_predicted) == type(sparse.csr_matrix([])):\n",
    "        y_predicted = y_predicted.toarray()\n",
    "    if type(y_true) == type(sparse.csr_matrix([])):\n",
    "        y_true = y_true.toarray()\n",
    "    n, m = y_true.shape\n",
    "    dcg = []\n",
    "    argsort = y_predicted.argsort(axis=1)[:, ::-1]\n",
    "    for i in range(n):\n",
    "        most_recommended = argsort[i][:k]\n",
    "        true_ratings = y_true[i][most_recommended]\n",
    "        dcg.append(np.sum(g(true_ratings) * d(np.arange(k))))\n",
    "    dcg = np.array(dcg)\n",
    "    return (dcg / max_dcg).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (0.5 балла)** Разделите индексы пользователей в матрицах из п.1 на 3 группы:\n",
    "1. пользователи, оценившие менее 20 фильмов;\n",
    "2. 50 случайных пользователей, оценивших фильмы, имеющие не более 5 оценок;\n",
    "3. все остальные пользователи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "less_20_rates = [x[0] for x in grouped if x[1].shape[0] < 20]\n",
    "print(len(less_20_rates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая группа пуста - каждый пользователь оценил хотя бы 20 фильмов.\n",
    "\n",
    "Отберем вторую группу. Для этого посмотрим, сколько раз был оценен каждый фильм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из 10109 фильмов 2248 имеют не более 5 оценок\n"
     ]
    }
   ],
   "source": [
    "all_ratings_sm = sparse.csr_matrix((ratings['rating'], (ratings['compressed_userID'], ratings['compressed_movieID'])))\n",
    "ratings_by_movies = all_ratings_sm.nonzero()[1]\n",
    "counter = collections.Counter(ratings_by_movies)\n",
    "rarely_rated = [i for i in range(n_movies) if counter[i] <= 5]\n",
    "print('Из {} фильмов {} имеют не более 5 оценок'.format(n_movies, len(rarely_rated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 916 пользователей, оценивших непопулярные фильмы\n"
     ]
    }
   ],
   "source": [
    "our_users = set()\n",
    "for movie in rarely_rated:\n",
    "    for user in all_ratings_sm.getcol(movie).tocsc().indices:\n",
    "        our_users.add(user)\n",
    "print('Всего {} пользователей, оценивших непопулярные фильмы'.format(len(our_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "group2 = set(random.sample(our_users, 50))\n",
    "group3 = set(range(n_users)) - group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой группы сделаем отдельные матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group2_train_sm = train_sm[list(group2)]\n",
    "group2_test_sm = test_sm[list(group2)]\n",
    "group2_val_sm = val_sm[list(group2)]\n",
    "group3_train_sm = train_sm[list(group3)]\n",
    "group3_test_sm = test_sm[list(group3)]\n",
    "group3_val_sm = val_sm[list(group3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. (0.5 балла)** Постройте рекомендации на основе **most popular** метода, при котором предсказанный рейтинг для некоторого фильма $i$ одинаков для всех пользователей и совпадает со средним значением рейтинга по всем пользователям, оценившим этот фильм, и вычислите значения метрик RMSE@5 и nDCG@5 для тестовой матрицы из п. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirillmouraviev/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "nonzero = train_sm.nonzero()\n",
    "ones = sparse.csr_matrix((np.ones_like(nonzero[0]), nonzero), shape=(n_users, n_movies))\n",
    "avg_rating = train_sm.sum(axis=0) / ones.sum(axis=0)\n",
    "avg_rating = np.array(np.nan_to_num(avg_rating))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_popular_prediction = np.tile(avg_rating, n_users).reshape((n_users, n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 172 ms, total: 4.78 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rmse = rmse_score(test_sm, most_popular_prediction)\n",
    "ndcg = ndcg_score(test_sm, most_popular_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.99816123591\n",
      "NDCG: 0.0005141536439\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', rmse)\n",
    "print('NDCG:', ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-30d9529ff51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод most popular предсказывает плохо, что не удивительно при сильно разреженной матрице."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. (1 балл)** Постройте рекомендации на основе user-based коллаборативной фильтрации (подробно метод описан в [лекции 19](https://github.com/esokolov/ml-course-hse/blob/master/2016-spring/lecture-notes/lecture19-recommender.pdf), в качестве функции сходства используйте корреляцию Пирсона), при этом итоговое предсказание модели $\\hat{r}_{ui}$ вычисляйте по следующей формуле:\n",
    "$$\\hat{r}_{ui} = \\bar{r}_{u} + \\frac{\\sum_{v \\in U(u)} w_{uv} (r_{vi} - \\bar{r}_v)}{\\sum_{v \\in U(u)} w_{uv}},$$\n",
    "где $\\bar{r}_u$ — средний ретинг пользователя $u$, $w_{uv}$ — мера сходства пользователей $u$ и $v$, $U(u) = \\{ v \\in U \\, | \\, w_{uv} > \\alpha\\}$ — коллаборация пользователя $u$. Значение параметра $\\alpha$ подберите на валидационной выборке.\n",
    "\n",
    "Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из группы 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Для начала построим матрицу похожестей пользователей $W = (w_{uv})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.corrcoef(train_sm.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $\\alpha$ от 0.1 до 0.5 с шагом 0.05 построим предсказание и посмотрим его RMSE и NDCG на валидации. Выберем то $\\alpha$, на котором RMSE больше всего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_based_collaborative_filtering(train_sm, alpha):\n",
    "    r_mean = train_sm.sum(axis=1) / ones.sum(axis=1)\n",
    "    r_mean = np.array(r_mean).T[0]\n",
    "    prediction = []\n",
    "    for u in range(n_users):\n",
    "        U = np.array(W[u] > alpha).nonzero()[0]\n",
    "        w = W[u][U]\n",
    "        R = train_sm[U, :]\n",
    "        sum_of_collab = w @ (R.T - r_mean[U]).T\n",
    "        sum_of_collab = np.array(sum_of_collab)[0]\n",
    "        our_prediction = r_mean[u] + sum_of_collab / w.sum()\n",
    "        prediction.append(our_prediction)\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for alpha in np.arange(0.5, 0.09, -0.05):\n",
    "    min_rmse = 5\n",
    "    prediction = user_based_collaborative_filtering(train_sm, alpha)\n",
    "    rmse = rmse_score(val_sm, prediction)\n",
    "    ndcg = ndcg_score(val_sm, prediction)\n",
    "    print('alpha = {}, rmse: {}, ndcg: {}'.format(alpha, rmse, ndcg))\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        best_alpha = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим прогноз с best_alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = user_based_collaborative_filtering(train_sm, best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. (0.5 балла)** Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1 и 2 (по отдельности) для рекомендаций, построенных в п. 5. Ощутимо ли различие со значениями метрик из п. 5? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Группа 1 пустая. Посмотрим RMSE и nDCG на группе 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_for_group2 = prediction[list(group2)]\n",
    "rmse = rmse_score(group2_test_sm, prediction_for_group2)\n",
    "ndcg = ndcg_score(group2_test_sm, prediction_for_group2)\n",
    "print('RMSE:', rmse)\n",
    "print('NDCG:', ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE почти не изменилось. NDCG стало нулевым. Причина, скорее всего, в том, что у пользователей, которые смотрят непопулярные фильмы, очень мало других похожих пользователей, и user-based подход не может на них хорошо работать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. (2 балла)** Постройте рекомендации при помощи модели со скрытыми переменными. Напомним, что в данном методе решается следующая оптимизационная задача:\n",
    "$$\\sum_{(u, i) \\in R} (r_{ui} - \\bar{r}_u - \\bar{r}_i - \\langle p_u, q_i\\rangle)^2 + \\lambda \\sum_{u \\in U} \\| p_u\\|^2 + \\mu \\sum_{i \\in I} \\| q_i\\|^2 \\to \\min_{p_u, q_i}$$\n",
    "\n",
    "Реализуйте построение рекомендаций при помощи любого из изученных методов оптимизации для данной задачи (SGD, ALS, HALS), подберите значения параметров регуляризации на валидационной выборке и постройте график зависимости метрик RMSE@5 и nDCG@5 от значения ранга разложения на валидационной выборке (рассмотрите как минимум 10 различных значений ранга разложения). Также разрешается использовать любые свободно распространяемые библиотеки при условии, что функционал совпадает с приведенным выше и используется один из приведенных методов оптимизации. Обращаем ваше внимание, что в оптимизационной задаче суммирование ведется лишь по известным элементам матрицы $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Будем использовать стохастический градиентный спуск (SGD). Изначально вектора $p_u$ и $q_i$ заполнены случайными значениями. На каждом шаге случайно выбирается пара $(u, i)$, и вектора $p_u$ и $q_i$ изменяются в сторону антиградиента:\n",
    "$$p_{uk}\\ \\text{+=}\\ \\eta(q_{ik}(r_{ui} - \\overline{r_u} - \\overline{r_i} - \\langle p_u, q_i\\rangle) - \\lambda p_{uk});\\ \\ \\ q_{ik}\\ \\text{+=}\\ \\eta(p_{uk}(r_{ui} - \\overline{r_u} - \\overline{r_i} - \\langle p_u, q_i\\rangle) - \\mu q_{ik})$$\n",
    "Возьмем для начала $\\eta = 0.001, \\lambda = \\mu = 0.1, d = 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def SGD(R, n_iter=1000, eta_0=0.05, lmbd=10, mu=10, d=20, verbose=10, batch_size=50):\n",
    "    means_by_user = R.mean(axis=1)\n",
    "    means_by_movie = R.mean(axis=0)\n",
    "    means_by_user = np.array(means_by_user).T[0]\n",
    "    means_by_movie = np.array(means_by_movie)[0]\n",
    "    #print(means_by_user.shape)\n",
    "    #print(means_by_movie.shape)\n",
    "    p = np.random.random((n_users, d)) * 5\n",
    "    q = np.random.random((n_movies, d)) * 5\n",
    "    tiled_mu = np.tile(means_by_user, n_movies).reshape((n_movies, n_users)).T\n",
    "    tiled_mm = np.tile(means_by_movie, n_users).reshape((n_users, n_movies))\n",
    "    R_normed = R - tiled_mu - tiled_mm\n",
    "    for iteration in range(n_iter):\n",
    "        eta = eta_0 / np.sqrt(iteration + 1)\n",
    "        u = np.random.randint(n_users, size=batch_size)\n",
    "        i = np.random.randint(n_movies, size=batch_size)\n",
    "        print(tiled_mu[u].shape)\n",
    "        m_u = tiled_mu[u][:, i]\n",
    "        m_i = tiled_mm[u][:, i]\n",
    "        print(type(m_u), m_u.shape)\n",
    "        print(type(m_i), m_i.shape)\n",
    "        print((R[u].toarray().T)[i].shape)\n",
    "        func = (R[u].toarray().T)[i] - m_u - means_by_movie[i] - (p[u] * q[i])\n",
    "        print(func.mean())\n",
    "        p[u] += eta * (func.mean() * q[i] - lmbd * p[u])\n",
    "        q[i] += eta * (func.mean() * p[u] - mu * q[i])\n",
    "        if iteration % verbose == 0:\n",
    "            our_funct = np.sum(np.array(R_normed - p @ q.T) ** 2)\n",
    "            print('iteration {}: without reg: {}, with reg: {}'.format(iteration,\\\n",
    "                                                                       our_funct,\\\n",
    "                                                                       our_funct + lmbd * np.sum(p ** 2) + mu * np.sum(q ** 2)))\n",
    "        break\n",
    "        \n",
    "SGD(train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. (0.5 балла)** Постройте рекомендации с оптимальными значениями гиперпараметров из п. 7 и вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1, 2 и 3 (по отдельности). Ощутимо ли различие между ними? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. (0.5 балла)** Реализуйте построение рекомендаций путём разложения матрицы рейтингов с помощью [разреженного SVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) (в предположении, что неизвестные рейтинги заменяются на нули) и последующего её восстановления и постройте график зависимости метрик RMSE@5 и nDCG@5 от значения ранга разложения на валидационной выборке (рассмотрите как минимум 10 различных значений ранга разложения). Постройте рекомендации с оптимальными значениями гиперпараметров  и вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для пользователей из групп 1, 2 и 3 (по отдельности). Как полученные значения отличаются от аналогичных из п. 8? Как это можно объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. (0.5 балла)** Сформируйте обучающие, валидационные и тестовые матрицы объект-признак для следующих наборов признаков:\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование);\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + средняя оценка пользователя;\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + жанры фильма;\n",
    " * id пользователя (бинарное кодирование) + id фильма (бинарное кодирование) + жанры фильма + киноперсоны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. (1.5 балла)** Для каждой из выборок из предыдущего пункта постройте рекомендации при помощи факторизационных машин из библиотеки [LibFM](http://libfm.org) с использованием метода оптимизации ALS, подобрав оптимальную размерность разложения на валидационной выборке. Вычислите значения метрик RMSE@5 и nDCG@5 на тестовой выборке для оптимальных значений гиперпараметров. Какой набор признаков оказался самым удачным? Как это можно объяснить?\n",
    "При выполнении данного задания вам также может пригодиться библиотека [pywFM](https://github.com/jfloff/pywFM), являющаяся python-обёрткой над LibFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. (1 балл)** Приведите сравнение качества всех моделей, руководствуясь значениями описанных метрик. Какие из моделей оказались лучше других по каждой из метрик? Как это можно объяснить?\n",
    "\n",
    "**Ответ**:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
